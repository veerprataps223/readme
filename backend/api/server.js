import express from "express";
import fetch from "node-fetch";
import dotenv from "dotenv";
import cors from "cors";

dotenv.config();
const app = express();

app.use(express.json({ limit: '10mb' }));

// Updated CORS configuration for production
app.use(cors({
  origin: [
    'http://localhost:3000', 
    'http://localhost:5173',
    'https://readme-livid.vercel.app/', // Replace with your actual Vercel URL
    /\.vercel\.app$/, // Allow all Vercel preview deployments
    /\.netlify\.app$/, // If you switch to Netlify
  ],
  credentials: true,
  methods: ['GET', 'POST', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization']
}));

// Add preflight handling
app.options('*', cors());

const PORT = process.env.PORT || 5000;
const GITHUB_API = "https://api.github.com";
const GEMINI_API = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent";

// Test Gemini API connection
async function testGeminiAPI() {
  if (!process.env.GEMINI_API_KEY) {
    console.log('âŒ No Gemini API key found');
    return { success: false, error: 'No API key' };
  }

  try {
    console.log('\nðŸ§ª Testing Gemini 2.0 Flash API...');
    const response = await fetch(`${GEMINI_API}?key=${process.env.GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: "Hello! Please respond with 'Gemini 2.0 Flash API is working!' to confirm the connection."
          }]
        }]
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.log('âŒ Gemini API error:', response.status, errorText);
      return { success: false, error: `HTTP ${response.status}: ${errorText}` };
    }

    const data = await response.json();
    const generatedText = data.candidates?.[0]?.content?.parts?.[0]?.text || 'No response';
    
    console.log('âœ… Gemini 2.0 Flash API Response:', generatedText);
    return { success: true, response: generatedText };
    
  } catch (error) {
    console.log('âŒ Gemini API test failed:', error.message);
    return { success: false, error: error.message };
  }
}

// Clean markdown response by removing first 12 characters and closing backticks
function cleanMarkdownResponse(text) {
  if (!text) return '';

  let cleaned = text.trim();

  // Remove opening ```markdown or ``` if present
  cleaned = cleaned.replace(/^```(?:markdown)?\s*/i, '');

  // Remove closing ```
  cleaned = cleaned.replace(/```$/, '').trim();

  return cleaned;
}

// Generate README using Gemini API
async function generateReadmeWithGemini(repoInfo, files, repoData) {
  if (!process.env.GEMINI_API_KEY) {
    throw new Error('Gemini API key not configured');
  }

  // Analyze file content for context
  const fileAnalysis = analyzeFiles(files);
  
  const prompt = `You are a technical documentation expert. Generate a comprehensive, professional README.md for this GitHub repository:

**Repository:** ${repoData.full_name}
**Description:** ${repoData.description || 'No description provided'}
**Language:** ${repoData.language || 'Not specified'}
**Stars:** ${repoData.stargazers_count || 0}
**Files Analysis:**
${fileAnalysis}

**Requirements:**
1. Create a complete, professional README.md
2. Include appropriate sections: Title(Title should be bolder and bigger or should look different than other headings), Description, Features, Usage, Installation,tech stack etc.
3. You can go a little more aggressive or deep within description , usage and features
4. Make sure chronological order is title , description, features, usage, tech stack, installation and other things etc...
4. Add relevant badges if applicable
5. Include code examples if you can infer usage patterns
6. Make it engaging and informative
7. Use proper Markdown formatting
8. Keep it concise but comprehensive

CRITICAL: Return ONLY raw markdown content. Do NOT wrap it in code blocks. Do NOT use \`\`\`markdown. Start directly with # title. No code fences whatsoever.`;

  try {
    const response = await fetch(`${GEMINI_API}?key=${process.env.GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: prompt
          }]
        }],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 2048,
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Gemini API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const generatedReadme = data.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (!generatedReadme) {
      throw new Error('No content generated by Gemini API');
    }

    // Clean the response to remove any markdown code block wrappers
    const cleanedReadme = cleanMarkdownResponse(generatedReadme);
    
    console.log('ðŸ§¹ Cleaned markdown response (removed code block wrappers)');
    
    return cleanedReadme;
    
  } catch (error) {
    console.error('Gemini API generation failed:', error.message);
    throw error;
  }
}

// Analyze files to provide context to Gemini
// Enhanced analyze files function - replace the existing analyzeFiles function with this
// Enhanced analyze files function - replace the existing analyzeFiles function with this
async function analyzeFiles(files) {
  const analysis = {
    totalFiles: files.length,
    languages: new Set(),
    frameworks: new Set(),
    libraries: new Set(),
    hasTests: false,
    hasDocker: false,
    hasCICD: false,
    hasReadme: false,
    configFiles: [],
    mainFiles: [],
    projectType: 'Unknown',
    dependencies: new Set(),
    detectedTechnologies: new Set()
  };

  // Configuration file contents to analyze
  let requirementsTxt = '';
  let setupPy = '';
  let packageJson = '';
  let pyprojectToml = '';

  // First pass - filename analysis and identify key files
  files.forEach(file => {
    const name = file.name.toLowerCase();
    const ext = name.split('.').pop();
    
    // Language detection
    const langMap = {
      'js': 'JavaScript', 'ts': 'TypeScript', 'py': 'Python', 'java': 'Java',
      'cpp': 'C++', 'c': 'C', 'rb': 'Ruby', 'php': 'PHP', 'go': 'Go',
      'rs': 'Rust', 'swift': 'Swift', 'kt': 'Kotlin', 'scala': 'Scala',
      'r': 'R', 'jl': 'Julia', 'sh': 'Shell', 'yml': 'YAML', 'yaml': 'YAML'
    };
    if (langMap[ext]) analysis.languages.add(langMap[ext]);

    // Framework/Technology detection from filenames
    if (name === 'package.json') {
      analysis.frameworks.add('Node.js');
      analysis.configFiles.push(file.name);
    }
    if (name === 'requirements.txt' || name === 'setup.py' || name === 'pyproject.toml') {
      analysis.frameworks.add('Python');
      analysis.configFiles.push(file.name);
    }
    if (name === 'pom.xml' || name === 'build.gradle') {
      analysis.frameworks.add('Java');
      analysis.configFiles.push(file.name);
    }
    if (name === 'cargo.toml') {
      analysis.frameworks.add('Rust');
      analysis.configFiles.push(file.name);
    }
    if (name === 'go.mod') {
      analysis.frameworks.add('Go');
      analysis.configFiles.push(file.name);
    }

    // Special files detection
    if (name.includes('test') || name.includes('spec')) analysis.hasTests = true;
    if (name === 'dockerfile' || name === 'docker-compose.yml') analysis.hasDocker = true;
    if (name.includes('ci') || name.includes('workflow') || name === '.travis.yml' || name === '.github') analysis.hasCICD = true;
    if (name === 'readme.md') analysis.hasReadme = true;

    // Main files
    if (['index.js', 'main.py', 'app.js', 'server.js', 'main.go', '__init__.py'].includes(name)) {
      analysis.mainFiles.push(file.name);
    }

    // Python-specific detection
    if (ext === 'py') {
      // Detect common Python ML/DS patterns from filenames
      if (name.includes('model') || name.includes('train') || name.includes('predict')) {
        analysis.detectedTechnologies.add('Machine Learning');
      }
      if (name.includes('data') || name.includes('preprocess')) {
        analysis.detectedTechnologies.add('Data Processing');
      }
    }

    // JavaScript/TypeScript specific detection
    if (ext === 'js' || ext === 'ts') {
      if (name.includes('component') || name.includes('hook')) {
        analysis.detectedTechnologies.add('React');
      }
      if (name.includes('test') || name.includes('spec')) {
        analysis.detectedTechnologies.add('Testing');
      }
    }
  });

  // Try to fetch and analyze key configuration files
  try {
    // Analyze Python dependencies
    const requirementsFile = files.find(f => f.name.toLowerCase() === 'requirements.txt');
    const setupFile = files.find(f => f.name.toLowerCase() === 'setup.py');
    const pyprojectFile = files.find(f => f.name.toLowerCase() === 'pyproject.toml');

    if (requirementsFile && requirementsFile.download_url) {
      try {
        const response = await fetch(requirementsFile.download_url);
        if (response.ok) {
          requirementsTxt = await response.text();
          analyzePythonDependencies(requirementsTxt, analysis);
        }
      } catch (error) {
        console.log('Could not fetch requirements.txt:', error.message);
      }
    }

    if (setupFile && setupFile.download_url) {
      try {
        const response = await fetch(setupFile.download_url);
        if (response.ok) {
          setupPy = await response.text();
          analyzeSetupPy(setupPy, analysis);
        }
      } catch (error) {
        console.log('Could not fetch setup.py:', error.message);
      }
    }

    // Analyze package.json for Node.js projects
    const packageFile = files.find(f => f.name.toLowerCase() === 'package.json');
    if (packageFile && packageFile.download_url) {
      try {
        const response = await fetch(packageFile.download_url);
        if (response.ok) {
          packageJson = await response.text();
          analyzePackageJson(packageJson, analysis);
        }
      } catch (error) {
        console.log('Could not fetch package.json:', error.message);
      }
    }

  } catch (error) {
    console.log('Error analyzing configuration files:', error.message);
  }

  // Determine project type based on detected technologies and dependencies
  determineProjectType(analysis);

  return formatAnalysisOutput(analysis);
}

function analyzePythonDependencies(content, analysis) {
  const lines = content.split('\n');
  const commonLibraries = {
    'numpy': 'NumPy',
    'pandas': 'Pandas', 
    'scikit-learn': 'Scikit-Learn',
    'sklearn': 'Scikit-Learn',
    'tensorflow': 'TensorFlow',
    'torch': 'PyTorch',
    'pytorch': 'PyTorch',
    'matplotlib': 'Matplotlib',
    'seaborn': 'Seaborn',
    'flask': 'Flask',
    'django': 'Django',
    'fastapi': 'FastAPI',
    'requests': 'Requests',
    'pytest': 'Pytest',
    'opencv': 'OpenCV',
    'cv2': 'OpenCV',
    'scipy': 'SciPy',
    'jupyter': 'Jupyter',
    'notebook': 'Jupyter Notebook',
    'streamlit': 'Streamlit',
    'plotly': 'Plotly',
    'sqlalchemy': 'SQLAlchemy',
    'celery': 'Celery',
    'redis': 'Redis',
    'nltk': 'NLTK',
    'spacy': 'spaCy',
    'keras': 'Keras'
  };

  lines.forEach(line => {
    const cleanLine = line.toLowerCase().trim().split(/[>=<]/)[0].trim();
    if (commonLibraries[cleanLine]) {
      analysis.libraries.add(commonLibraries[cleanLine]);
      analysis.dependencies.add(cleanLine);
    }
    
    // Check for ML/DS indicators
    if (cleanLine.includes('scikit') || cleanLine.includes('sklearn') || cleanLine.includes('tensorflow') || cleanLine.includes('torch')) {
      analysis.detectedTechnologies.add('Machine Learning');
    }
    if (cleanLine.includes('pandas') || cleanLine.includes('numpy')) {
      analysis.detectedTechnologies.add('Data Science');
    }
    if (cleanLine.includes('flask') || cleanLine.includes('django') || cleanLine.includes('fastapi')) {
      analysis.detectedTechnologies.add('Web Framework');
    }
  });
}

function analyzeSetupPy(content, analysis) {
  // Extract dependencies from setup.py
  const installRequiresMatch = content.match(/install_requires\s*=\s*\[(.*?)\]/s);
  if (installRequiresMatch) {
    const deps = installRequiresMatch[1].replace(/['"]/g, '').split(',');
    deps.forEach(dep => {
      const cleanDep = dep.trim().toLowerCase().split(/[>=<]/)[0].trim();
      analysis.dependencies.add(cleanDep);
      
      // Check for common libraries
      if (cleanDep.includes('scikit') || cleanDep.includes('sklearn')) {
        analysis.libraries.add('Scikit-Learn');
        analysis.detectedTechnologies.add('Machine Learning');
      }
      if (cleanDep.includes('numpy')) {
        analysis.libraries.add('NumPy');
      }
      if (cleanDep.includes('pandas')) {
        analysis.libraries.add('Pandas');
        analysis.detectedTechnologies.add('Data Science');
      }
    });
  }

  // Extract project description/name for type detection
  const nameMatch = content.match(/name\s*=\s*['"](.*?)['"]/);
  if (nameMatch) {
    const projectName = nameMatch[1].toLowerCase();
    if (projectName.includes('ml') || projectName.includes('learn') || projectName.includes('model')) {
      analysis.detectedTechnologies.add('Machine Learning');
    }
  }
}

function analyzePackageJson(content, analysis) {
  try {
    const pkg = JSON.parse(content);
    const allDeps = { ...pkg.dependencies, ...pkg.devDependencies };
    
    Object.keys(allDeps).forEach(dep => {
      const depName = dep.toLowerCase();
      
      // React ecosystem
      if (depName.includes('react')) {
        analysis.libraries.add('React');
        analysis.detectedTechnologies.add('Frontend Framework');
      }
      if (depName.includes('vue')) {
        analysis.libraries.add('Vue.js');
        analysis.detectedTechnologies.add('Frontend Framework');
      }
      if (depName.includes('angular')) {
        analysis.libraries.add('Angular');
        analysis.detectedTechnologies.add('Frontend Framework');
      }
      
      // Backend
      if (depName.includes('express')) {
        analysis.libraries.add('Express.js');
        analysis.detectedTechnologies.add('Web Framework');
      }
      if (depName.includes('next')) {
        analysis.libraries.add('Next.js');
        analysis.detectedTechnologies.add('Full-Stack Framework');
      }
      
      // Testing
      if (depName.includes('jest') || depName.includes('mocha') || depName.includes('chai')) {
        analysis.detectedTechnologies.add('Testing');
      }
    });
  } catch (error) {
    console.log('Error parsing package.json:', error.message);
  }
}

function determineProjectType(analysis) {
  const techs = Array.from(analysis.detectedTechnologies);
  const libs = Array.from(analysis.libraries);
  
  if (libs.some(lib => ['Scikit-Learn', 'TensorFlow', 'PyTorch'].includes(lib))) {
    analysis.projectType = 'Machine Learning Library';
  } else if (techs.includes('Machine Learning')) {
    analysis.projectType = 'Machine Learning Project';
  } else if (techs.includes('Data Science') || libs.includes('Pandas')) {
    analysis.projectType = 'Data Science Project';
  } else if (techs.includes('Web Framework')) {
    analysis.projectType = 'Web Application';
  } else if (techs.includes('Frontend Framework')) {
    analysis.projectType = 'Frontend Application';
  } else if (analysis.languages.has('Python')) {
    analysis.projectType = 'Python Project';
  } else if (analysis.languages.has('JavaScript')) {
    analysis.projectType = 'JavaScript Project';
  }
}

function formatAnalysisOutput(analysis) {
  // Combine technologies for display
  const allTechnologies = new Set([
    ...Array.from(analysis.languages),
    ...Array.from(analysis.frameworks),
    ...Array.from(analysis.libraries),
    ...Array.from(analysis.detectedTechnologies)
  ]);

  return `
- Total files: ${analysis.totalFiles}
- Project Type: ${analysis.projectType}
- Languages: ${Array.from(analysis.languages).join(', ') || 'Unknown'}
- Technologies: ${Array.from(allTechnologies).join(', ') || 'None detected'}
- Key Libraries: ${Array.from(analysis.libraries).join(', ') || 'None detected'}
- Has tests: ${analysis.hasTests ? 'Yes' : 'No'}
- Has Docker: ${analysis.hasDocker ? 'Yes' : 'No'}
- Has CI/CD: ${analysis.hasCICD ? 'Yes' : 'No'}
- Config files: ${analysis.configFiles.join(', ') || 'None'}
- Main files: ${analysis.mainFiles.join(', ') || 'None'}
- Key files found: ${files.slice(0, 10).map(f => f.name).join(', ')}
- Dependencies detected: ${analysis.dependencies.size} packages`;
}

// Debug function to check GitHub API status
async function checkGitHubRateLimit() {
  const headers = { 
    "User-Agent": "readme-generator-debug",
    "Accept": "application/vnd.github.v3+json"
  };
  
  if (process.env.GITHUB_TOKEN) {
    headers.Authorization = `Bearer ${process.env.GITHUB_TOKEN}`;
  }

  try {
    const res = await fetch(`${GITHUB_API}/rate_limit`, { headers });
    const data = await res.json();
    
    console.log('\nðŸ” GitHub API Rate Limit Status:');
    console.log(`- Core API: ${data.resources.core.remaining}/${data.resources.core.limit} remaining`);
    console.log(`- Reset time: ${new Date(data.resources.core.reset * 1000).toLocaleTimeString()}`);
    console.log(`- Authentication: ${process.env.GITHUB_TOKEN ? 'âœ… Using token' : 'âŒ Unauthenticated'}\n`);
    
    return data;
  } catch (error) {
    console.error('âŒ Failed to check rate limit:', error.message);
    return null;
  }
}

// Fetch repository files
async function fetchRepoFiles(owner, repo, path = "", depth = 0) {
  if (depth > 2) return []; // Limit depth to prevent too many requests
  
  const url = `${GITHUB_API}/repos/${owner}/${repo}/contents/${path}`;
  const headers = { 
    "User-Agent": "readme-generator",
    "Accept": "application/vnd.github.v3+json"
  };
  
  if (process.env.GITHUB_TOKEN) {
    headers.Authorization = `Bearer ${process.env.GITHUB_TOKEN}`;
  }

  try {
    const res = await fetch(url, { headers, timeout: 10000 });
    
    if (!res.ok) {
      if (res.status === 403) {
        const rateLimitReset = res.headers.get('x-ratelimit-reset');
        const resetTime = new Date(parseInt(rateLimitReset) * 1000);
        throw new Error(`Rate limit exceeded. Resets at: ${resetTime.toLocaleTimeString()}`);
      } else if (res.status === 404) {
        throw new Error("Repository not found or path doesn't exist");
      }
      const errorText = await res.text();
      throw new Error(`GitHub API error: ${res.status} - ${errorText}`);
    }
    
    const items = await res.json();
    if (!Array.isArray(items)) return [];
    
    let files = [];
    for (const item of items.slice(0, 30)) { // Limit items
      if (item.type === "file") {
        files.push({
          name: item.name,
          path: item.path,
          size: item.size || 0,
          download_url: item.download_url
        });
      } else if (item.type === "dir" && depth < 1) {
        // Only go one level deep for now
        const subFiles = await fetchRepoFiles(owner, repo, item.path, depth + 1);
        files = files.concat(subFiles);
      }
    }
    
    return files;
    
  } catch (error) {
    console.error(`âŒ Error fetching files from ${path}:`, error.message);
    if (depth === 0) throw error;
    return [];
  }
}

// Parse GitHub URL
function parseGitHubUrl(url) {
  const patterns = [
    /github\.com\/([^\/]+)\/([^\/]+?)(?:\.git)?(?:\/.*)?$/,
    /^([^\/\s]+)\/([^\/\s]+)$/
  ];
  
  for (const pattern of patterns) {
    const match = url.trim().match(pattern);
    if (match) {
      return { owner: match[1], repo: match[2] };
    }
  }
  return null;
}

// Test endpoint for Gemini API
app.get("/test-gemini", async (req, res) => {
  try {
    console.log('\n' + '='.repeat(50));
    console.log('ðŸ¤– Testing Gemini 2.0 Flash API Connection');
    console.log('='.repeat(50));
    console.log('Request received from:', req.get('origin') || req.get('referer') || 'unknown');
    
    const result = await testGeminiAPI();
    
    const response = {
      success: result.success,
      message: result.success ? "Gemini 2.0 Flash API is working!" : "Gemini API test failed",
      model: "gemini-2.0-flash-exp",
      response: result.response || null,
      error: result.error || null,
      hasApiKey: !!process.env.GEMINI_API_KEY,
      timestamp: new Date().toISOString(),
      server: 'render',
      environment: process.env.NODE_ENV || 'development'
    };

    console.log('Sending response:', { success: response.success, hasApiKey: response.hasApiKey });
    
    res.json(response);
    
  } catch (error) {
    console.error('Test endpoint error:', error.message);
    res.status(500).json({
      success: false,
      message: "Test failed",
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// Enhanced main endpoint with Gemini integration
app.post("/generate-readme", async (req, res) => {
  try {
    console.log('\n' + '='.repeat(50));
    console.log('ðŸš€ README Generation Started (Gemini 2.0 Flash)');
    console.log('='.repeat(50));
    
    const { repoUrl } = req.body;
    
    if (!repoUrl) {
      return res.status(400).json({ error: "Repository URL is required" });
    }

    // Check rate limit before starting
    const rateLimitInfo = await checkGitHubRateLimit();
    if (rateLimitInfo && rateLimitInfo.resources.core.remaining < 5) {
      const resetTime = new Date(rateLimitInfo.resources.core.reset * 1000);
      return res.status(429).json({ 
        error: `Rate limit nearly exceeded. Try again after ${resetTime.toLocaleTimeString()}` 
      });
    }

    // Parse GitHub URL
    const repoInfo = parseGitHubUrl(repoUrl);
    if (!repoInfo) {
      return res.status(400).json({ 
        error: "Invalid GitHub URL format. Use: https://github.com/owner/repository" 
      });
    }

    // Get repository data
    console.log(`\nðŸ“¡ Fetching repository: ${repoInfo.owner}/${repoInfo.repo}`);
    const repoResponse = await fetch(`${GITHUB_API}/repos/${repoInfo.owner}/${repoInfo.repo}`, {
      headers: {
        "User-Agent": "readme-generator",
        "Accept": "application/vnd.github.v3+json",
        ...(process.env.GITHUB_TOKEN && { Authorization: `Bearer ${process.env.GITHUB_TOKEN}` })
      }
    });

    if (!repoResponse.ok) {
      if (repoResponse.status === 404) {
        return res.status(404).json({ error: "Repository not found or is private" });
      }
      throw new Error(`GitHub API error: ${repoResponse.status}`);
    }

    const repoData = await repoResponse.json();
    console.log(`âœ… Repository found: ${repoData.full_name}`);

    // Fetch files
    console.log('ðŸ“ Fetching repository files...');
    const files = await fetchRepoFiles(repoInfo.owner, repoInfo.repo);
    
    if (files.length === 0) {
      throw new Error("No accessible files found in repository");
    }

    console.log(`ðŸ“„ Found ${files.length} files`);

    // Generate README with Gemini 2.0 Flash
    console.log('ðŸ¤– Generating README with Gemini 2.0 Flash AI...');
    const readme = await generateReadmeWithGemini(repoInfo, files, repoData);

    // File analysis for response
    const fileAnalysis = analyzeFiles(files);
    const analysis = {
      mainLanguage: repoData.language || Array.from(new Set(files.map(f => {
        const ext = f.name.split('.').pop();
        const langMap = { 'js': 'JavaScript', 'ts': 'TypeScript', 'py': 'Python' };
        return langMap[ext];
      }).filter(Boolean)))[0] || "Unknown",
      languages: Array.from(new Set(files.map(f => {
        const ext = f.name.split('.').pop();
        const langMap = { 'js': 'JavaScript', 'ts': 'TypeScript', 'py': 'Python', 'java': 'Java' };
        return langMap[ext];
      }).filter(Boolean))),
      totalFiles: files.length,
      analyzedFiles: files.length,
      hasTests: files.some(f => f.name.toLowerCase().includes('test')),
      hasDocker: files.some(f => f.name.toLowerCase() === 'dockerfile'),
      hasCICD: files.some(f => f.name.includes('ci') || f.name.includes('workflow'))
    };

    console.log('âœ… Enhanced README generated successfully with deep analysis');
    
    res.json({
      readme,
      analysis: {
        ...analysis,
        deepAnalysis: {
          projectType: 'Enhanced analysis completed',
          tokensUsed: 'Up to 8192 tokens',
          enhancedFeatures: [
            'File content analysis',
            'Dependency detection', 
            'API endpoint discovery',
            'Architecture insights',
            'Deployment guidance'
          ]
        }
      },
      model: "gemini-2.0-flash-exp",
      repository: {
        name: repoData.full_name,
        description: repoData.description,
        stars: repoData.stargazers_count,
        language: repoData.language
      }
    });

  } catch (error) {
    console.error('\nâŒ Generation failed:', error.message);
    
    if (error.message.includes('Rate limit')) {
      res.status(429).json({ error: error.message });
    } else if (error.message.includes('not found')) {
      res.status(404).json({ error: "Repository not found or is private" });
    } else if (error.message.includes('Gemini')) {
      res.status(500).json({ error: `AI Generation failed: ${error.message}` });
    } else {
      res.status(500).json({ error: error.message });
    }
  }
});

// Health check with both GitHub and Gemini API tests
app.get("/health", async (req, res) => {
  try {
    const [rateLimitInfo, geminiTest] = await Promise.all([
      checkGitHubRateLimit(),
      testGeminiAPI()
    ]);
    
    res.json({
      status: "healthy",
      timestamp: new Date().toISOString(),
      environment: {
        hasGeminiKey: !!process.env.GEMINI_API_KEY,
        hasGithubToken: !!process.env.GITHUB_TOKEN,
        nodeVersion: process.version,
        port: PORT,
        nodeEnv: process.env.NODE_ENV
      },
      github: {
        rateLimitRemaining: rateLimitInfo?.resources.core.remaining || 'unknown',
        rateLimitTotal: rateLimitInfo?.resources.core.limit || 'unknown',
        status: rateLimitInfo ? 'connected' : 'error'
      },
      gemini: {
        model: "gemini-2.0-flash-exp",
        status: geminiTest.success ? 'connected' : 'error',
        error: geminiTest.error || null
      }
    });
  } catch (error) {
    res.status(500).json({
      status: "unhealthy",
      error: error.message
    });
  }
});

// Add a simple root endpoint for testing
app.get("/", (req, res) => {
  res.json({
    message: "README Generator API",
    version: "2.0",
    endpoints: ["/health", "/test-gemini", "/generate-readme"],
    timestamp: new Date().toISOString()
  });
});

app.listen(PORT, async () => {
  console.log(`ðŸš€ Enhanced Server running on http://localhost:${PORT}`);
  console.log(`ðŸ“Š Health check: http://localhost:${PORT}/health`);
  console.log(`ðŸ¤– Test Gemini 2.0 Flash: GET http://localhost:${PORT}/test-gemini`);
  console.log(`ðŸ”‘ GitHub Token: ${process.env.GITHUB_TOKEN ? 'âœ…' : 'âŒ'}`);
  console.log(`ðŸ”‘ Gemini Key: ${process.env.GEMINI_API_KEY ? 'âœ…' : 'âŒ'}`);
  console.log(`ðŸ”¥ Using Gemini 2.0 Flash model`);
  console.log(`ðŸŒ Environment: ${process.env.NODE_ENV || 'development'}`);
  
  // Test both APIs on startup
  setTimeout(async () => {
    await checkGitHubRateLimit();
    await testGeminiAPI();
  }, 1000);
});

export default app;